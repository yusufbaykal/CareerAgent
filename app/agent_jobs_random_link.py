import asyncio
import logging
from textwrap import dedent
from urllib.parse import urlparse
from pathlib import Path
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.log import logger
import dotenv
dotenv.load_dotenv()
from Tool.DocumentParserToolkit import DocumentParserToolkit
from Tool.WebScraperToolkit import WebScraperToolkit
from Tool.JobAnalysisToolkit import JobAnalysisToolkit
from Tool.FileToolkit import FileToolkit    
import sys
import re

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def generate_filename_from_url(url: str) -> str:
    parsed_url = urlparse(url)
    domain = parsed_url.netloc.split('.')[0]
    path_parts = [p for p in parsed_url.path.split('/') if p]
    position_keywords = ["developer", "engineer", "manager", "analyst", "specialist", "assistant"]
    position = ""
    for part in path_parts:
        for keyword in position_keywords:
            if keyword in part.lower():
                position = part
                break
        if position:
            break                
    if not position and path_parts:
        position = path_parts[-1]
    
    position = re.sub(r'[^a-zA-Z0-9]', '_', position)
    filename = f"{domain}_{position}"
    
    return filename

async def create_job_analysis_agent() -> Agent:
    doc_parser = DocumentParserToolkit()
    web_scraper = WebScraperToolkit()
    job_analyzer = JobAnalysisToolkit()
    file_toolkit = FileToolkit()
    
    instructions = dedent("""\
        Sen bir iÅŸ ilanÄ± analiz uzmanÄ±sÄ±n. KullanÄ±cÄ±lara farklÄ± kaynaklardan gelen iÅŸ ilanlarÄ±nÄ±
        anlamlandÄ±rmalarÄ±na ve analiz etmelerine yardÄ±mcÄ± olursun.
        
        ğŸš¨ KRÄ°TÄ°K UYARI: SADECE JSON FORMATINDA KAYDET! TXT FORMATINDA ASLA KAYDETME! ğŸš¨
        
        ## Ä°Å Ä°LANI ANALÄ°Z ADIMLARI:
        
        1. **Ä°LAN KAYNAÄI BELÄ°RLE:**
           - Dosya: parse_document() kullan
           - URL: fetch_url_content() veya fetch_linkedin_job() kullan
           - LinkedIn Arama: search_linkedin_jobs() kullan
        
        2. **Ä°LANI ANALÄ°Z ET:**
           - analyze_job_description() ile detaylÄ± analiz yap
           - extract_job_details() ile yapÄ±landÄ±rÄ±lmÄ±ÅŸ formata dÃ¶nÃ¼ÅŸtÃ¼r
        
        3. **SONUÃ‡LARI JSON OLARAK KAYDET:**
           - save_json(data=ANALIZ_SONUÃ‡LARI, file_path="dosya.json") kullan
           - MUTLAKA .json uzantÄ±sÄ± ile kaydet
        
        ## GEREKLÄ° JSON YAPISI:
        ```json
        {
          "summary": "Pozisyon Ã¶zeti",
          "company_information": "Åirket bilgisi", 
          "mission_vision": "Misyon ve vizyon",
          "position_details": "Pozisyon detaylarÄ±",
          "experience_level": "Junior/Mid-level/Senior",
          "work_environment": "Uzaktan/Hibrit/Ofis", 
          "years_of_experience": "X+ yÄ±l",
          "tech_stack": ["teknoloji1", "teknoloji2"],
          "requirements": ["gereksinim1", "gereksinim2"],
          "responsibilities": ["sorumluluk1", "sorumluluk2"],
          "nice_to_have": ["isteÄŸe_baÄŸlÄ±1", "isteÄŸe_baÄŸlÄ±2"],
          "benefits": ["avantaj1", "avantaj2"],
          "culture_hints": ["kÃ¼ltÃ¼r_ipucu1", "kÃ¼ltÃ¼r_ipucu2"],
          "motivation_points": ["motivasyon_noktasÄ±1", "motivasyon_noktasÄ±2"]
        }
        ```
        
        ## ANALÄ°Z EDÄ°LECEK BÄ°LGÄ°LER:
        - Pozisyon baÅŸlÄ±ÄŸÄ± ve seviyesi (Junior/Mid-level/Senior)
        - Åirket bilgileri, misyon/vizyon
        - Ã‡alÄ±ÅŸma ortamÄ± (Uzaktan/Hibrit/Ofis)
        - Deneyim gereksinimleri
        - Teknik beceriler (tech_stack)
        - Gereksinimler ve sorumluluklar
        - Ä°steÄŸe baÄŸlÄ± beceriler (nice_to_have)
        - Avantajlar ve ÅŸirket kÃ¼ltÃ¼rÃ¼ ipuÃ§larÄ±
        - Motivasyon noktalarÄ±
        
        ## KAYDETME KURALLARI:
        - âŒ save_text() YASAK!
        - âŒ .txt dosyasÄ± YASAK!
        - âœ… save_json() ZORUNLU!
        - âœ… .json uzantÄ±sÄ± ZORUNLU!
        - âœ… YukarÄ±daki JSON yapÄ±sÄ±na UYGUN olmalÄ±!
        
        Analiz sonuÃ§larÄ±nÄ± temiz, dÃ¼zenli ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir formatta sunmaya Ã¶zen gÃ¶ster.
    """)
    
    return Agent(
        model=OpenAIChat(
            id="gpt-4o",
        ),
        tools=[doc_parser, web_scraper, job_analyzer, file_toolkit],
        instructions=instructions,
        markdown=True,
        show_tool_calls=True,
    )


async def run_agent(message: str) -> str:
    try:
        url_match = re.search(r'https?://[^\s]+', message)
        if url_match:
            url = url_match.group(0)            
            filename = generate_filename_from_url(url)
            project_root = Path(__file__).parent.parent
            output_dir = project_root / "Jobs" / "Job_Analysis"
            output_dir.mkdir(parents=True, exist_ok=True)
            file_path = output_dir / f"{filename}.json"
            if "dosyasÄ±na kaydet" not in message:
                message = f"{message} ve sonuÃ§larÄ± {file_path} dosyasÄ±na kaydet."
        
        logger.info(f"Job Analysis Agent baÅŸlatÄ±lÄ±yor, sorgu: '{message}'")
        
        agent = await create_job_analysis_agent()
        
        result = await agent.arun(message)
        
        return result
                
    except Exception as e:
        logger.error(f"Agent Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return f"âŒ Hata: {str(e)}"


if __name__ == "__main__":
    message = sys.argv[1] if len(sys.argv) > 1 else "https://hubx.breezy.hr/p/100f78632ca7-backend-developer adresindeki iÅŸ ilanÄ±nÄ± analiz et"
    
    asyncio.run(run_agent(message))